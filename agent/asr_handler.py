# agent/asr_handler.py
import pyaudio
import os
import dashscope
import logging
from dashscope.audio.asr import Recognition, RecognitionCallback, RecognitionResult
import config
import threading
import time
import numpy as np

logger = logging.getLogger(__name__)

class ASRHandler:
    def __init__(self, on_sentence_end_callback):
        self.on_sentence_end_callback = on_sentence_end_callback
        self.mic = None
        self.stream = None
        self.recognition = None
        self._is_running = False
        self._connection_lost = threading.Event()

        class ASRCallback(RecognitionCallback):
            def __init__(self, outer_instance):
                self.outer = outer_instance
            def on_open(self) -> None:
                logger.info("ğŸ¤ è¯­éŸ³è¯†åˆ«æœåŠ¡å·²è¿æ¥ï¼Œè¯·å¼€å§‹è¯´è¯...")
                try:
                    self.outer.mic = pyaudio.PyAudio()
                    self.outer.stream = self.outer.mic.open(
                        format=pyaudio.paInt16,
                        channels=config.CHANNELS,
                        rate=config.SAMPLE_RATE,
                        input=True
                    )
                    self.outer._is_running = True
                    self.outer._connection_lost.clear()
                except Exception as e:
                    logger.error(f"æ‰“å¼€éº¦å…‹é£å¤±è´¥: {e}")
                    self.outer._connection_lost.set()
            def on_close(self) -> None:
                logger.info("ğŸ¤ è¯­éŸ³è¯†åˆ«æœåŠ¡å·²å…³é—­ã€‚")
                self.outer._is_running = False
                if self.outer.stream:
                    if self.outer.stream.is_active():
                        self.outer.stream.stop_stream()
                    self.outer.stream.close()
                if self.outer.mic:
                    self.outer.mic.terminate()
                self.outer.stream = self.outer.mic = None
            def on_error(self, message) -> None:
                logger.error(f"è¯­éŸ³è¯†åˆ«å‡ºé”™: {message.message}")
                self.outer._connection_lost.set()
                self.on_close()
            def on_event(self, result: RecognitionResult) -> None:
                sentence = result.get_sentence()
                if 'text' in sentence and RecognitionResult.is_sentence_end(sentence):
                    user_text = sentence['text']
                    logger.info(f"è¯†åˆ«åˆ°ä½ è¯´: {user_text}")
                    if self.outer.on_sentence_end_callback:
                        self.outer.on_sentence_end_callback(user_text)
        
        self.callback = ASRCallback(self)
        self.recognition = Recognition(
            model=config.ASR_MODEL,
            format=config.FORMAT_PCM,
            sample_rate=config.SAMPLE_RATE,
            callback=self.callback
        )

    def start_session(self):
        self.recognition.start()
        logger.info("ASRä¼šè¯å·²å¯åŠ¨ã€‚")

    def run_audio_loop(self):
        """è¿è¡ŒéŸ³é¢‘å‘é€å¾ªç¯ï¼Œç›´åˆ°è¿æ¥æ–­å¼€ï¼Œå¹¶å¢åŠ äº†VADé€»è¾‘ã€‚"""
        
        # --- VAD é€»è¾‘åˆå§‹åŒ– ---
        last_speech_time = time.time()
        
        while self._is_running and not self._connection_lost.is_set():
            try:
                if self.stream and not self.stream.is_stopped():
                    data = self.stream.read(config.BLOCK_SIZE, exception_on_overflow=False)
                    
                    # --- VAD æ ¸å¿ƒè®¡ç®— ---
                    # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
                    audio_data = np.frombuffer(data, dtype=np.int16)
                    # è®¡ç®—éŸ³é‡ï¼ˆRMSèƒ½é‡ï¼‰
                    if audio_data.size > 0:
                        # å…ˆå°†æ•°æ®è½¬ä¸º64ä½æµ®ç‚¹æ•°å†è®¡ç®—ï¼Œé¿å…æ•´æ•°å¹³æ–¹æº¢å‡ºé—®é¢˜
                        audio_data_fp = audio_data.astype(np.float64)
                        # è®¡ç®—éŸ³é‡ï¼ˆRMSèƒ½é‡ï¼‰
                        energy = np.sqrt(np.mean(audio_data_fp**2))
                        # logger.debug(f"å½“å‰éŸ³é¢‘èƒ½é‡: {energy:.2f}")  # æ³¨é‡Šæ‰é¢‘ç¹çš„è°ƒè¯•ä¿¡æ¯
                    else:
                        # å¦‚æœéŸ³é¢‘å—ä¸ºç©ºï¼Œåˆ™èƒ½é‡ä¸º0
                        energy = 0
                    
                    # --- VAD åˆ¤æ–­é€»è¾‘ ---
                    if energy > config.VAD_ENERGY_THRESHOLD:
                        # æ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ›´æ–°è¯´è¯æ—¶é—´ï¼Œå¹¶å‘é€æ•°æ®
                        last_speech_time = time.time()
                        self.recognition.send_audio_frame(data)
                    else:
                        # å¤„äºé™é»˜çŠ¶æ€
                        self.recognition.send_audio_frame(data) # å³ä½¿é™é»˜ä¹Ÿå‘é€æ•°æ®ï¼Œè®©æœåŠ¡ç«¯å¤„ç†
                        if time.time() - last_speech_time > config.SILENCE_TIMEOUT_SECONDS:
                            logger.info(f"æ£€æµ‹åˆ°è¶…è¿‡ {config.SILENCE_TIMEOUT_SECONDS} ç§’çš„æŒç»­é™é»˜ï¼Œå°†ä¸»åŠ¨é‡ç½®è¿æ¥ä»¥ä¿æŒæ´»æ€§...")
                            self.stop() # ä¸»åŠ¨åœæ­¢
                            break # é€€å‡ºå¾ªç¯ï¼Œè®©å®ˆæŠ¤è¿›ç¨‹æ¥ç®¡

                else:
                    break 
            except (IOError, OSError) as e:
                logger.error(f"éŸ³é¢‘è¯»å–é”™è¯¯: {e}")
                self._connection_lost.set()
                break
    
    def stop(self):
        """å¤–éƒ¨è°ƒç”¨çš„åœæ­¢æ–¹æ³•ã€‚"""
        if self._is_running:
            self._is_running = False
            self._connection_lost.set() # å‘é€åœæ­¢ä¿¡å·
            if self.recognition:
                self.recognition.stop()
